\chapter{Test Driven Development}
\section{Overview on software testing}
Software testing is an essential part of the development process and lifecycle of a system, as it helps to verify that an implemented solution is reliable and performs as intended in most situations. Testing can be defined as the process of finding differences between the expected behavior specified by the system's requirements and models, and the observed behavior of the implemented software; unfortunately, it is impossible to completely test a non-trivial system. First, testing is not decidable; second, testing must be performed under time and budget constraints \cite{OOSE}, therefore testing every possible configuration of the parameters of a system is unfeasible.
Today, developers often compromise on testing activities by identifying only a critical subset of features to be tested.

There are many approaches to software testing, including unit testing, integration testing, system testing, as well as performance, penetration and acceptance testing. Each of these approaches has its own specific goals and methods, as well as a different suite of tools built to support them and ensure that the testing process is always consistent, its execution is easily automated, and the test outcomes are always clear; furthermore, they are often used in combination with each other to ensure that a software product is thoroughly tested and conform to its specification. 
More in detail, the main testing techniques are: 
\begin{itemize}
    \item \textbf{Unit Testing} is a method of testing individual units or components of a software product in isolation; its goal is to verify that each unit of code is working correctly and meets the specified requirements. These kinds of tests are usually written by the developers who also wrote the corresponding production code, and they are run automatically as part of the build process. Techniques also exist to generate input configuration for unit test automatically, by searching amongst the input space for the program.
    \item \textbf{Integration Testing} is a method of testing how different units or components of a software product work together. The goal of integration testing is to ensure that the different parts of the system are integrated correctly and that they function as expected when combined. Integration tests are typically more complex than unit tests, as they involve multiple units of code working together.
    \item \textbf{System Testing} is a method of testing a complete software product in a simulated or real-world environment. The goal of system testing is to ensure that the software meets the specified requirements and performs as expected when running in a real-world environment. System tests may involve testing the software on different hardware or operating systems, or with different data inputs and configurations.
    \item \textbf{Acceptance Testing} is a method of testing a software product to ensure that it meets the needs and expectations of the end user. The goal of acceptance testing is to verify that the software is fit for its intended purpose and that it meets the requirements of the user. Acceptance tests are often written by the end user or a representative of the end user, and they may involve testing the software in a real-world environment
    \item \textbf{Performance Testing} is the process of evaluating a system's performance in terms of responsiveness and stability under a particular workload; it is usually done to determine how a system behaves in terms of various inputs and how it responds to different levels of traffic. \dots Used to test availability, reliability, and other parameters.
    \item \textbf{Penetration Testing} is the practice of testing a system, network, or application  with the objective of identifying vulnerabilities that an attacker could exploit. This security evaluation of the system happens by simulating an attack and identifying any weaknesses that could be exploited by a malicious party. Penetration testing can be conducted by both internal and external security teams and is often used as a means to identify and remediate any potential security risks.
\end{itemize}



\subsection{Software Development Lifecycle}
Before discussing how testing activities are performed in more detail, it is essential to introduced how testing is integrated in the development process. The term Software Development Lifecycle (SDLC) refers to the entire process of developing and maintaining software systems, from the initial concept, to its end-of-life period.

One of the first SDLC models introduced in software engineering is the Waterfall model; it is a linear, sequential approach to software development in which there is a strict, marked division between the different phases, such as requirements gathering, design, implementation, testing, and maintenance.
The main weakness of this model is that it does not allow for much iteration or flexibility: once a phase is completed, it is difficult to go back and make changes to earlier phases; this can lead to a very long feedback cycle between requirements specification and system testing, resulting in wasted time and resources in case a design flaw is not discovered until later in the development process. Additionally, the Waterfall model assumes that all requirements can be fully gathered and understood at the beginning of the project; such a simplification is often not applicable in modern software development, where ever-evolving requirements and functionalities are the norm. 
Finally, the model does not account for the fact that testing and deployment are ongoing processes, not a single event at the end of the project.
Figure \ref{waterfall_model} highlights the main phases of the Waterfall model.

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm, scale=0.5]{figures/waterfall_model.png}
    \caption{The Waterfall model}
    \label{waterfall_model}
\end{figure}

Modern software development strays away from non-incremental models, as today's applications are continuously evolving and adapting; instead, iterative approaches are preferred, where the sequential chain of the Waterfall model is replaced by a cyclical process during which the development team goes through multiple iterations or cycles of planning, designing, building, testing, and evaluating the product.

A key example is the Agile SLDC model, which values flexibility and collaboration, and prioritizes customer satisfaction and working software over strict plans and documentation. One of the main principles of Agile development is the use of small, cross-functional teams that work together to deliver working software in short sprints or iterations: this allows for frequent feedback and adjustments to be made throughout the development process between the clients and the development teams, rather than waiting until the end of a project to make changes.
Figure \ref{agile_model} highlights the phases of the Agile process:

\begin{figure}[h]
    \centering
    \includegraphics[width=8cm, scale=0.2]{figures/agile_model.jpg}
    \caption{The Agile model}
    \label{agile_model}
\end{figure}

\noindent The main steps performed during each of these phases are summarized below:
\begin{itemize}
    \item \textbf{Design}: in this phase, the team designs the architecture, user interface and overall functionality of the software; the design process is iterative and collaborative, with the team working closely with customers, as well as with the stakeholders, with the objective to ensure that the software meets the agreed-upon needs.
    \item \textbf{Code \& Test}: in this phase, the team writes the code for the software and performs testing to ensure that it is functioning correctly; agile development places a strong emphasis on automated testing, which allows for quick feedback on the quality of the delivered code modules.
    \item \textbf{Release}: the team releases the software to customers and stakeholders for feedback; this allows the team to gather feedback on the software and make any necessary adjustments before the final release.
    \item \textbf{Feedback}: the team reviews the feedback received from customers and stakeholders and makes any necessary changes to the software. Feedback is incorporated into the development process in an iterative manner, allowing the software to continuously improve over time.
    \item \textbf{Meet \& Plan}: the team meets to plan the next iteration of development, reviews the progress made in the previous iteration, sets goals for the next iteration, and assigns tasks to team members. The team also reviews and adjusts the development plan as needed to ensure that the software is on track to meet the customers' needs.
\end{itemize}



\section{Test-Driven Development}
\subsection{Overview}
Unit testing is arguably the most used testing technique since by itself it can already provide a general assessment of the quality and reliability of a software solution. \tdd is a software development approach that builds on top of the concept of unit testing; it was firstly introduced in 2003 by Kent Back in the book "Test-Driven Development By Example" \cite{TDDByExample}; while there is no formal definition of the process, as the author states, the goal is to "write clean code that works". With \tdd, test cases are written before any production code is written; these tests are used to define the requirements for the system and to guide the development process. 
The end goal of this practice is for all tests to pass before the development is complete, by continuously running the entire test suite as more features are tested and built; this can help to ensure the quality and reliability of software. Moreover, \tdd encourages software developers to write small, isolated units of code that are easy to test, maintain and understand, and will ultimately act themselves as a form of documentation for the developers. 
Compared to traditional SDLC approaches, \tdd is an extremely short, incremental, and repetitive process, and is related to \textbf{test-first programming} concepts in agile development and extreme programming; this advocates for frequent updates/releases for the software, in short cycles, while encouraging code reviews, unit testing and incremental addition of features.


At its core, \tdd is made up of three iterative phases: "\textit{Red}", "\textit{Green}" and "\textit{Blue}" (or "\textit{Refactor}"):
\begin{itemize}
    \item In the \textbf{\textit{Red}} phase, a test case is written for the chunk of functionality to be implemented; since the corresponding logic does not exist yet, the test will obviously fail, often not even compiling.
    \item In the \textbf{\textit{Green}} phase, only the code that is strictly required to make the test pass is written.
    \item Finally, in the \textbf\textit{{Blue}} phase, the implemented code, as well as the respective test cases, is refactored and improved. It is important to perform regression testing after the refactoring to ensure that the changes didn't result in any unexpected behaviors in other components.
\end{itemize}
Each new unit of code requires a repetition of this cycle \cite{GuidelinesTDD}.

Figure \ref{tdd-cycle} provides a visual representation of the \tdd cycle:
\begin{figure}[h]
    \centering
    \includegraphics[width=8cm, scale=0.2]{figures/tdd_cycle.jpg}
    \caption{The Test Driven Development cycle}
    \label{tdd-cycle}
\end{figure}

As previously stated, each \tdd iteration should be extremely short, usually spanning from 10 to 15 minutes at most; this is possible thanks to a meticulous decomposition of the system's requirements into a set of \textbf{User Stories}, each detailing a small chunk of a functionality specified in the requirements. These stories can then be prioritized and implemented iteratively.

User stories can vary in granularity: when using a fine-grained structure when describing the task, this can be broken up into a set of sub-tasks, each corresponding to a small feature; on the other hand, with coarser-grained tasks, this division is less pronounced \cite{DBLP:journals/tse/KaracTJ21}. Even when the same task is considered, the outcome of the \tdd process will change depending on the level of granularity employed when describing it; there is no overall right or wrong approach, rather it is something that comes from the experience of the developer to break tasks into small work items \cite{DBLP:journals/tse/KaracTJ21}.

The general mantra of \tdd revolves around the "Make it green, then make it clean" motto

\subsection{\tdd advantages}
The employment of \tdd can result in a series of benefits during the development process, such as:
\begin{itemize}
    \item \textbf{Regression testing}: by incrementally building a test suite as the different iterations of \tdd are performed, we ensure that the system  
    \item \textbf{Very high code coverage}: coverage is a metric used to determine how much of the code is being tested; it can be expressed according to different criteria such as statement coverage, i.e., how many statements in the code are reached by the test cases, branch coverage, i.e., how many conditional branches are executed during testing, or function coverage, i.e., how many functions are executed when running the test suite. While different coverage criteria result in different benefits, by employing \tdd we ensure that any segment of code written has at least one associated test case.
    \item \textbf{Improved code quality}: as we are specifically writing code to pass the tests in place, and refactoring it after the "Green" phase, we ensure that the code is cleaner and overall more optimized, without any extra pieces of functionalities that may not be needed. 
    \item \textbf{Improved code readability and documentation}: test act as documentation...
    \item \textbf{Simplified debugging and early fault detection}: Whenever a test fails it becomes obvious which component has caused the fault: by adopting this incremental approach and performing regression testing, if a test fail we will be certain that the newly written code will be responsible. For this reason, faults are detected extremely early during the testing process, rather than potentially remaining hidden until the whole test suite has been built and executed.
\end{itemize}


