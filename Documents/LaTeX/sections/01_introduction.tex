Things to add:
\begin{itemize}
    \item where different types of coverage are useful
    \item Add formulas for coverage criteria
\end{itemize}


\subsection*{Coverage testing}
Coverage is one of the metrics employed during testing to asses what portion of the source code is "covered" by the test suite i.e., 
what portion of the code is executed when the tests run. Coverage is essential to extract information about the general quality of a test suite
and helps determine how comprehensively the software is being verified.
As a result, coverage can be classified as a white-box testing technique.


Source code coverage can be expressed according to different sub-metrics:
\begin {itemize}
    \item Statement coverage aims executing every single statement in the code.
    \item Branch coverage, also known as decision coverage, measures how many decision structure have been fully explored by the test cases.
    \item Mutation coverage, also known as fault-based testing, aims at purposefully introducing faults in the program in order to 
            check whether the test suite is able to identify them. If the fault is correctly detected, the mutant is "killed".
            One issue of mutation is scalability, since generating and compiling the mutants, before running the test cases, can be time-consuming end quickly exhaust testing resources. Additionally, the introduced mutations can be classified as weak or strong: with strong mutation, the artificial fault is propagated to an observable behavior, while weak mutants are confined to more 
            specific environments.
    \item Function coverage measures how many functions have been called by the test cases.
    \item Condition coverage determines the number of boolean conditions/expressions executed in the conditional statements.
\end {itemize}

To reach statement coverage, it is sufficient to execute a branch in which the statement is control dependent.

A high coverage can sometimes be deceiving, however: in the case of Machine Learning Systems (MLS), where typically the source code is made up 
of a sequence of library functions and API invocations \cite{article2}, thus resulting in very high statement and branch coverage with relatively modest
test suites.
Additionally, the effectiveness of such systems is highly determined by the dataset employed for model training and validation, which
cannot be covered by tradition test cases.

Coverage can also be measured at any testing levels; while at the unit test-level we focus mostly on the coverage of statements and branches,
at the system-testing level, the coverage targets shift towards more complex elements, such as menu items, business transactions or other
operations that require multiple components of the system to work properly.

A coverage criterion is 
A coverage goal is a particular target that we want to cover in respect to the chosen criterion, i.e. a particular branch of an if statement.

\subsection*{Automatic test case generation}
Test case generation can be seen as a multi-objective problem, given that the goal is to cfover multiple test targets.

Search-based approaches for test case generation use optimization algorithms to attempt to find 
the best candidate test case with the objective to maximize fault detection. Genetic Algorithms (GAs) are an example of an
evolutionary search approach for test case generation; starting from an initial, often randomlly genrated, population of 
test cases, the algorithm keeps evolving the individuals according to simulated natural evolution theory principles.
In this context, a typical fitness function of a GA would measure the distance between the execution trace of the generated test cases
and the coverage targets.


\subsection*{Testing in the Internet of Things}