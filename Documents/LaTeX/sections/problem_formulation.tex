\newpage
\section{An overview on search problems}
As humans, everyday we perform search: from looking for our car keys in the house to searching for a new book to purchase, this action is engraved in our daily life.
In the same way, search is one of the most fundamental operations on which computer science has focused since its early days: performing efficient search is the core operation of many classes of algorithms, such as the ones responsible for route planning, computer vision, robotics, automated software testing, puzzle solving, and many others.


Any search problem is typically defined by: 
\begin{itemize}
    \item A search space: the set of elements in which we search for our solution. Examples include paths in a graph, the numbers to insert in a sorted list, or the web pages accesses by a web index.
    \item A condition that defines the characteristics of candidate solutions.
\end{itemize}

\textbf{formal problem definition with graphs, distance functions, ...}

A search algorithm will therefore examine the search space according to some criteria and attempt to find a suitable solution. Finding any candidate solution is just one of the objective of search problems however, often times we are interested in finding the best possible solution, the optimum; such problems are referred to as optimization problems.

The exploration of the search space can happen in many different ways. The most basic approach consists of exploring the elements one by one, till a solution/the optimum is found, in a brute-force manner. Applying this simple solution for problems whose search space is somewhat limited can be done without too many repercussions on execution time, however, given the exponential size of the search spaces of most practical problems, a brute-force approach is infeasible. 

For problems in which we have no choice but to employ brute-force search, there may be some room for improvement by using heuristics. Heuristics are estimates of the distance function to reach a goal state from the current node \cite{HeuristicSearch}.


Therefore, what it is preferred to obtain a solution that may not be the optimum, but rather it is "good enough" for our objective. This approach is called local search.

 
\textbf{Hill climbing, simulated annealing, GAs...}
Genetic Algorithms (GAs) are an example of an
evolutionary search approach for test case generation; starting from an initial, often randomly generated, population of 
test cases, the algorithm keeps evolving the individuals according to simulated natural evolution theory principles.
In this context, a typical fitness function of a GA would measure the distance between the execution trace of the generated test cases
and the coverage targets.





\newpage
\section{Driving simulators for self-driving vehicles}

\begin{itemize}
    \item BeamNG
    \item CARLA \cite{Dosovitskiy17} is another open source simulator built specifically for self-driving vehicles in mind. Similarly to BeamNG, it features an API written in Python to actively interact with the simulation any manipulate traffic, pedestrians, weather conditions and more parameters.
    Furthermore, an interesting feature of CARLA is its runtime texture streaming; this features allows developers to change the texture of every object in the scene during runtime. Such a feature can be particularly useful to tune a driving model to continuously deal with adversarial attacks.
    Finally, CARLA simulations can run without rendering any asset, thus allowing runs to be executed much quicker.
    \item Mathematical models: 

\end{itemize}


\newpage
\section{Adversarial attacks}

Most vision-based recognition software on ADS is based on CNNS; often, CNN-based deep learning models are vulnerable to the so called adversarial, 

There can be small, pixel-level changes to an image that will cause the AI model to incorrectly interpret it or, on the other hand, a completely new image can be used to trick to model into thinking it is something else. The first kind is particularly dangerous, since such changes can be invisible to the human eye, and thus harder to detect.

There are mainly two categories of methods to achieve adversarial attacks, namely, optimization-based methods and fast gradient step method (FGSM)-based approach.


study on street signs: K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao,
A. Prakash, T. Kohno, and D. Song, “Robust Physical-World Attacks on
Deep Learning Visual Classification,” in 2018 IEEE/CVF Conference on
Computer Vision and Pattern Recognition. IEEE, 2018, pp. 1625–1634.


In general, adversarial attacks are organized in three categories: evasion, poisoning, and extraction attacks:
\begin{itemize}
    \item Evasion attacks modify the input to a classifier such that it is misclassified, while keeping the modification as small as possible. Evasion attacks can be black-box or white-box: in the white-box case, the attacker has full access to the architecture and parameters of the classifier. For a black-box attack, clearly this is not the case.
    \item In poisoning attacks, attackers have the opportunity of manipulating the training data to significantly decrease the overall performance, cause targeted misclassification or bad behavior, and insert backdoors and neural trojans
    \item Extraction attacks aim to develop a new model, starting from a proprietary black-box model, that emulate the behavior of the original model.
\end{itemize}
