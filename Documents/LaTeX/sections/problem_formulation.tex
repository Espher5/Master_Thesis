\section{Coverage testing}
Coverage is one of the metrics employed during testing to assess what portion of the source code is "covered" by the test suite i.e., 
what portion of the code is executed when the tests run; it is essential to extract information about the general quality of a test suite and helps determine how comprehensively the software is being verified. As a result, coverage can be classified as a white-box testing technique.\newline
Source code coverage can be expressed according to different criteria:
\begin {itemize}
    \item Statement coverage aims executing every single statement in the code.
    \item Branch coverage, also known as decision coverage, measures how many decision structure have been fully explored by the test cases. Out of all the branches in a program, some may be unreachable/infeasible \cite{DBLP:conf/issta/YatesM89}, i.e. there is no input configuration that will result in their execution, due to a developer error; as a result, when performing coverage testing, such branches may pose a threat since, if undetected, may drain test budget.
    \item Mutation coverage, also known as fault-based testing, aims at purposefully introducing faults in the program in order to 
            check whether the test suite is able to identify them. If the fault is correctly detected, the mutant is "killed".
            One issue of mutation is scalability, since generating and compiling the mutants, before running the test cases, can be time-consuming end quickly exhaust testing resources. Additionally, the introduced mutations can be classified as weak or strong: with strong mutation, the artificial fault is propagated to an observable behavior, while weak mutants are confined to more 
            specific environments.
    \item Function coverage measures how many functions have been called by the test cases.
    \item Condition coverage determines the number of boolean conditions/expressions executed in the conditional statements.
\end {itemize}
To reach statement coverage, it is sufficient to execute a branch in which the statement is control dependent.

A high coverage can sometimes be deceiving, however: in the case of Machine Learning Systems (MLS), for example, where typically the source code is made up of a sequence of library functions and API invocations \cite{DBLP:journals/ese/RiccioJSHWT20}, thus resulting in very high statement and branch coverage with relatively modest
test suites. Additionally, the effectiveness of such systems is highly determined by the dataset employed for model training and validation, which cannot be covered by tradition test cases.

Coverage can also be measured at any testing levels; while at the unit test-level we focus mostly on the coverage of statements and branches, at the system-testing level, the coverage targets shift towards more complex elements, such as menu items, business transactions or other operations that require multiple components of the system to work properly.

A coverage goal is a particular target that we want to cover in respect to the chosen criterion, i.e. a particular branch of an if statement.


\section{An overview on search problems}
As humans, everyday we perform search: from looking for our car keys in the house to searching for a new book to purchase, this action is engraved in our daily life.
In the same way, search is one of the most fundamental operations on which computer science has focused since its early days: performing efficient search is the core operation of many classes of algorithms, such as the ones responsible for route planning, computer vision, robotics, automated software testing, puzzle solving, and many others.


Any search problem is typically defined by: 
\begin{itemize}
    \item A search space: the set of elements in which we search for our solution. Examples include paths in a graph, the numbers to insert in a sorted list, or the web pages accesses by a web index.
    \item A condition that defines the characteristics of candidate solutions.
\end{itemize}

\textbf{formal problem definition with graphs, distance functions, ...}

A search algorithm will therefore examine the search space according to some criteria and attempt to find a suitable solution. Finding any candidate solution is just one of the objective of search problems however, often times we are interested in finding the best possible solution, the optimum; such problems are referred to as optimization problems.

The exploration of the search space can happen in many different ways. The most basic approach consists of exploring the elements one by one, till a solution/the optimum is found, in a brute-force manner. Applying this simple solution for problems whose search space is somewhat limited can be done without too many repercussions on execution time, however, given the exponential size of the search spaces of most practical problems, a brute-force approach is infeasible. 

For problems in which we have no choice but to employ brute-force search, there may be some room for improvement by using heuristics. Heuristics are estimates of the distance function to reach a goal state from the current node \cite{HeuristicSearch}.


Therefore, what it is preferred to obtain a solution that may not be the optimum, but rather it is "good enough" for our objective. This approach is called local search.

 
\textbf{Hill climbing, simulated annealing, GAs...}
Genetic Algorithms (GAs) are an example of an
evolutionary search approach for test case generation; starting from an initial, often randomly generated, population of 
test cases, the algorithm keeps evolving the individuals according to simulated natural evolution theory principles.
In this context, a typical fitness function of a GA would measure the distance between the execution trace of the generated test cases
and the coverage targets.


\section{Search-based test case generation}
Search-based approaches for test case generation use optimization algorithms to attempt to find 
the best candidate test case with the objective to maximize fault detection. 


\section{Iterative single-target search}
The simplest way of approaching the evolutionary search problem for test case generation is by iteratively determining a coverage goal in the source code (i.e. a particular branch), and executing the GA to find a test case that achieves this coverage. 
A strategy for iterative search typically includes:
\begin{itemize}
    \item Enumerating the targets to cover, i.e. the individual branches.
    \item Performing the single-objective search for each target, until all the targets are covered, or the budget has expired.
    \item Building the final test suite by combining all the generated test cases.
\end{itemize}


Formally, the search problem for branch coverage can be formulated as follows:
\newtheorem{prob}{Problem}
\begin{prob}
    Let $ B = \{b_1,...,b_k\} $ be the set of branches in a program; find a test suite $ T = \{t_1,...,t_n \} $ of n test cases that covers all feasible branches, minimizing the fitness function:
    \begin{equation}
        min f_B (T) = |M| - |M_T| + \sum_{b \in B} d(b, T)
    \end{equation}
    where $|M|$ is the total number of methods, $|M_T|$ is the number of executed methods by all test cases in T, and d(b, T) indicates the minimal normalized branch distance for branch $ b \in B $
\end{prob}


Add infeasible branches

Focusing on one coverage goal at a time can be a poor strategy, however. Foremost, a search algorithms could get "trapped" while attempting to cover an expensive branch and waste a large portion of the testing budget \cite{DBLP:journals/tse/FraserA13}.
Secondly, the order by which coverage targets are selected may end up largely impacting the final performance.
Additionally, this approach assumes that all coverage goal are equally important and independent of each other; this is often not the case as, for example, covering the true branch of an if statement may be easier than covering the true branch of another if statement that requires a complex chain of operations to be properly satisfied. Finally, covering a particular branch may have collateral coverage over other branches in the test case's path.


\section{Whole test suite approach}
The issues with iterative search suggest that multi-target evolutionary approaches may reveal more effective and reliable. These are known as whole test suites approaches (WS) \cite{QSIC11} and their goal is to evolve the entire test suite simultaneously, rather than iteratively covering the single branches/statements; this eliminates the two issues of the iterative approach: the algorithms can't get stuck on an expensive branch, since the all coverage targets are being searched simultaneously and, for the same reason, the order of test case generation becomes irrelevant, preventing adversary influence in the final test suite.


In the context of the WS approach, the fitness function used is still one for the entire test suite and is computed as an aggregated value from the fitness values measured for the single test cases, in order to take into consideration all coverage targets simultaneously for the chosen criterion.

------------------------------------------------------------------------------------------
In fact, each test case in a test suite
is associated with the target closest to its execution trace.
The sum over all test cases of such minimum distances
from the targets provides the overall, test-suite-level fitness.
The additive combination of multiple targets into a single,
scalar objective function is known as sum scalarisation in
the theory of optimization \cite{SearchMethodologies}.
------------------------------------------------------------------------------------------

Branch coverage is typically the most used coverage criterion for test case generation. In this context, a fitness function
is based on two parameters: 
\begin{itemize}
    \item Approach level: represents how far the execution path of a given test case is from covering the target branch.
    \item Branch distance: represents how far the input data is from changing the conditional value of the branch.
\end{itemize}
Given that the branch distance can be arbitrarily greater than the approach level, usually this value is normalized \cite{DBLP:conf/icst/Arcuri10}.

------------------------------------------------------------------------------------------
While being more effective than the iterative approach, algorithms based on WS principles suffer from the problems of sum-scalarization in many-objective optimization, among which the inefficient convergence occurring in the non-convex regions of the search space
------------------------------------------------------------------------------------------

\section{Many-objective search}
The final approach consists in performing a many-objective search; here different coverage targets are considered different objectives to be optimized. 
Studies in literature \cite{DBLP:conf/ppsn/HandlLK08} have demonstrated that when applying many-objective search to a complex problem previously approached with single-objective search may bring improvements, since the probability of being trapped in a local maxima is reduced, also leading to a faster convergence rate \cite{DBLP:conf/icst/PanichellaKT15}.

The new problem can then be formulated as follows \cite{DBLP:journals/tse/PanichellaKT18}:

As a result of the nature of this problem, the fitness function doesn't stem from the aggregated fitness scores of the individual test cases anymore; rather, it is measured according to the multi-objective nature of optimality, with the goals of minimizing each of the fitness functions of the generated test case population.



