\newpage
\section{Autonomous Driving Vehicles}
\subsection{Introduction}




\subsection{History of autonomous vehicles}
Magnetic wire following cars \dots
The \textbf{Automatic Land Vehicle in Neural Networl}, ALVINN, was the first self-driving car ever proposed, in 1988; it was based on neural networks responsible to detect lines, segment the environment, and drive the car.
While the general principles on which it was based worked well, the limited computed capabilities at the time, didn't make the solution take off. Furthermore, the absence of data meant that it was extremely difficult to gather the necessary samples and datasets on which to base the models that would manage vision and driving.


\subsection{Sensors and hardware}
Autonomous vehicles employ both RGB cameras and LiDAR sensors to generate a representation of the surrounding environment, in the form of 2D RGB images and sparse 3D point clouds.



LiDAR stands for Light Detection And Ranging. It's a method to measure distance of object by firing a focused laser beam and measuring the time it takes for it to bounce back at the source after being reflected by something.
Compared to traditional camera images, LiDAR data can provide additional information about the surrounding scene...

A self-driving vehicle cannot rely on LiDAR alone, however. While this technology works great in most environments, including dark areas, if the scene surrounding the car becomes more noisy, due to rain or fog for example, the LiDAR sensor can become imprecise or fail.

For this reason, a third sensor is usually employed, the RADAR, which scans the surrounding area based on radio waves\dots





\section{Object detection}
Reliable object detection is a crucial requirement in realizing autonomous driving \cite{DBLP:journals/ftcgv/JanaiGBG20}; being aware of its surrounding environment is necessary to make an autonomous vehicle avoid accidents that may be life-threatening.

IoU: intersection of union

The complexity of the object detection problem varies according to different input modalities:
\begin{itemize}
    \item Video cameras are the cheapest solution
    \item LiDAR data 
    \item Camera images + LiDAR data. Most modern autonomous driving solutions employ both LiDAR and RGB camera sensors for perception. 
\end{itemize}

The multi-modal perception systems can be classified into two broad categories: cascaded models which use each modality independently, and fusion models which learn from different modalities simultaneously \cite{DBLP:conf/iros/AbdelfattahY0W21}.

In cascaded models, the images are used by a 2D detection DNN to generate proposals of search spaces where a car may reside; then, the LiDAR points corresponding to these regions are extracted for 3D point-based detection.

Fusion models, on the other hand, use DNNs to extract and fuse image and point cloud features in parallel. Then, a combined
representation is sent through another DNN for 3D detection.


To approach the problem, a detection pipeline must be established. Typically, the following steps are required:
\begin{itemize}
    \item Preprocessing.
    \item Region of Interest (ROT) extraction.
    \item Object classification.
    \item Verification.
\end{itemize}


Today's state of the art approaches for object detection employ Convolutional Neural Networks, CNNs \cite{DBLP:conf/eccv/CaiFFV16} \cite{DBLP:journals/pami/ChenKZMFU18}.
A problem with Deep CNNs with large receptive fields is that local information is extracted in the early layers, while higher-level represented in deeper layers \cite{DBLP:journals/ftcgv/JanaiGBG20}, making the precise localization of the object more difficult.
A solution to this problem was proposed by Girshick et al. \cite{DBLP:conf/cvpr/GirshickDDM14} with Region Based Convolutional Neural Networks, R-CNNs. This scalable approach solves the localization problem by generating many region proposals using selective search \cite{DBLP:journals/ijcv/UijlingsSGS13} to extract a fixed-length feature vector for each proposed region using a CNN and classifying each region with a linear SVM.




CNNs can capture different patterns 


\newpage
\section{3D Object detection}

\subsection{3D object detection from 2D images}

\subsection{3D object detection from 3D point clouds}
The goal of 3D object detection is to predict a three-dimensional bounding box around each object of interest.

Similarly to what happens with 2D detection, IoU can be used to evaluate the performance of a model.


\section*{Dataset}
\begin{itemize}
    \item Street signs: German Traffic Sign Recognition Benchmark
    \item Pedestrians, vehicles and 
\end{itemize}



\textbf{Formal definition}
\dots
In the case of self-driving vehicles specifically, we can assume a value of zero for roll and pitch since the car is "glued" to the road.
Frustum... [C. R. Qi, W. Liu, C. Wu, H. Su, and L. J. Guibas, “Frustum pointnets
for 3d object detection from rgb-d data,” in Proc. of the IEEE
Conference on Computer Vision and Pattern Recognition, 2018]



Only image: Monocular 3D Object Detection for Autonomous Driving and Geometru-based Distance Decompositon for Monocular 3D Object Detection or Pseudo-LiDAR

Only LiDAR: 

Both:





\newpage
\section{Adversarial attacks on neural networks}
As we've seen, most vision-based recognition software for ADS is based on DNNs; often, these models, especially CNN-based ones, are vulnerable to the adversarial attacks that aim at significantly alter the prediction capabilities of a model by slightly altering its input \cite{DBLP:journals/corr/GoodfellowSS14}.
These can be small, pixel-level changes to an image that will cause the AI model to incorrectly interpret it or, on the other hand, a completely new image can be used to trick to model into thinking it is something else. The first kind is particularly dangerous, since such changes can be invisible to the human eye, and thus harder to detect.





There are mainly two categories of methods to achieve adversarial attacks, namely, optimization-based methods and fast gradient step method (FGSM)-based approach.


In \cite{DBLP:journals/iotj/ZhangLWWLJ22}, Zhang et al. propose and end-to-end evaluation framework for assessing the safety of a self-driving deep learning models based on stereo images.



study on street signs: K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao,
A. Prakash, T. Kohno, and D. Song, “Robust Physical-World Attacks on
Deep Learning Visual Classification,” in 2018 IEEE/CVF Conference on
Computer Vision and Pattern Recognition. IEEE, 2018, pp. 1625–1634.


In general, adversarial attacks are organized in three categories: evasion, poisoning, and extraction attacks:
\begin{itemize}
    \item Evasion attacks modify the input to a classifier such that it is misclassified, while keeping the modification as small as possible. Evasion attacks can be black-box or white-box: in the white-box case, the attacker has full access to the architecture and parameters of the classifier. For a black-box attack, clearly this is not the case.
    \item In poisoning attacks, attackers have the opportunity of manipulating the training data to significantly decrease the overall performance, cause targeted misclassification or bad behavior, and insert backdoors and neural trojans
    \item Extraction attacks aim to develop a new model, starting from a proprietary black-box model, that emulate the behavior of the original model.
\end{itemize}
