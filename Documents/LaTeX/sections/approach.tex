In this chapter we will present in detail the planning and approach we followed to establish our study.

the two experimental tasks on which this study is based on, as well as the analysis of the gathered results.

The study was conducted with the participation of 9 undergraduate master's degree students enrolled in the "Embedded Systems" course at the University of Salerno in Italy. The participation voluntarily accepted to take part in this study.


\section{Research Questions}
The study we performed aimed at answering the following Research Questions (RQ):
\begin{itemize}
    \item \textbf{RQ1}:
    \item \textbf{RQ2}: Are there differences between TDD and NO-TDD in the external quality of the implemented solutions, developers’ productivity, and number of tests written?
    \item \textbf{RQ3}: Are there differences between TDD and NO-TDD in (cyclomatic, cognitive and code smells)
\end{itemize}




\section{Experimental Units}
The participants for this study were students at the University of Salerno, in Italy, they were a mix of second-year master's degree students at the University of Salerno and students visiting with the Erasmus program; this last group was further made up of master's degree student and third-year bachelor's degree students. Both groups were enrolled in the Embedded Systems course at the University of Salerno.

he course covered the following topics, software
quality, unit testing, integration testing, SOLID principles, refactor-
ing, iterative test-last development, big-bang testing, and TDD. The
course included frontal lectures, laboratory sessions, and home-
work. During the laboratory sessions, the students improved their
knowledge about how to develop unit tests in Java by using the
Eclipse IDE and JUnit, and the refactoring functionality available in
Eclipse. During laboratory sessions and by developing homework,
the students practiced unit testing, iterative test-last development,
big-bang testing, and TDD

Participating in this study was voluntary; the students were informed that any gathered data would be treated anonymously and shared for research purposes only. Furthermore, participation would not directly affect their final mark for the Embedded System course; however, in order to encourage student participation, those who took part in the study were rewarded with a bonus in their final mark. Among the students taking the course, 9 participated in this study.

The participants for the tasks were asked to carry out their assignment by either using TDD or no-TDD (i.e., any approach they preferred, except for TDD) depending on the group they were partitioned in. and on the period the task took place.



\section{Experimental Materials}
The experimental objects were three code katas, programming exercises aimed at practicing a technique or a programming language:
\begin{itemize}
    \item \textbf{IntelligentOffice}:
    \item \textbf{CleaningRobot}:
    \item \textbf{SmartHome}:
\end{itemize}



\section{Tasks}



\section{Variables}
Independent variables:
\begin{itemize}
    \item \textbf{Technique}: a nominal variable assuming two values, TDD and no-TDD.
    \item \textbf{Period}: since the study is longitudinal - i.e., the data was collected over time - we took into account the period during which each treatment (TDD or no-TDD) was applied.
    \item \textbf{Group}:  variable representing the two groups. It can assume the values G1 and G2.
\end{itemize}


Dependent variables:
\begin{itemize}
    \item \textbf{Quality (QLTY)}: quantifies the external quality of the solution a participant implemented. This variable is defined as follows: 
        \[
            QLTY = \frac{\sum_{i=1}^{\#TUS} QLTY_i}{\#TUS} * 100 
        \]
    where $\#TUS$ is the number of user stories a participant tackled, while $QLTY_i$ is the external quality of the $i-th$ user story; to determine whether a user story was tackled or not, we checked the asserts in the test suite corresponding to the story. Namely, if at least one assert in the test suite for the story passes, than the story was considered as tackled. $\#TUS$ is formally defined as follows:
        \[
            \#TUS = \sum_{i=1}^{n} 
                \begin{cases}
                    1 & \text{$\#ASSERT_i(PASS) > 0$}\\
                    0 & \text{otherwise}
                \end{cases}
        \]
    On the other hand, the quality of the $i-th$ user story (i.e., $QLTY_i$) is defined as the ratio of asserts passed for the acceptance suite of the $i-th$ user story over the total number of asserts in the acceptance suite for the same story. More formally:
        \[
            QLTY_i = \frac{\#ASSERT_i(PASS)}{\#ASSERT_i(ALL)}
        \]
    \item \textbf{Productivity (PROD)}: estimates the productivity of a participant. It is computed as follows:
        \[
            PROD = \frac{\#ASSERT(PASS)}{\#ASSERT(ALL)} * 100
        \]
    where $ASSERT(PASS)$ is the total number of asserts that have passed, by considering all acceptance test suites, while $ASSERT(ALL)$ refers to the total number of asserts in the acceptance suites. The $PROD$ variable can assume values between 0 and 100: a value close to 0 indicates low productivity in the implemented solution, while a value close to 1 refers to high productivity.
    \item \textbf{Number of tests (TEST)}: quantifies the number of unit tests a participant wrote. It is defined as the number of assert statements in the test suite written by the participant; this variable ranges from 0 to $\infty$.
\end{itemize}


Furthermore, we considered four additional dependent variables regarding the general code quality in the submitted projects were collected:
\begin{itemize}
    \item \textbf{Number of smells (SMELL)}:
    \item \textbf{Cyclomatic Complexity (CYC)}:
    \item \textbf{Cognitive Complexity (COG)}:
    \item \textbf{Lines of code (LOC)}: the number of lines of code written by the participant in both the production code and the test code.
\end{itemize}



\section{Study design}
The participants were randomly split into two groups, G1 and G2, having 4 and 5 participants respectively. For the first period P1, the group G1 was assigned the TDD task, while the group G2 was assigned the no-TDD task; on the other hand, during period P2, the group G1 was assigned the no-TDD task, while the group G2 was assigned the TDD task.
Therefore, the design of our study can be classified as a repeated-measures, within-subjects design. In each period, the participants in G1 and G2 dealt with different experimental objects. For instance, in P1, the participants in G1 dealt with BSK, while those in G2 with MRA. At the end of the study, every participant had tackled each experimental object only once.

\section{Procedure}
Before our study took place, we collected some demographic information on the participants. To this end, the participants were asked to fill out an on-line pre-questionnaire (created by means of Google Forms).

The Embedded Systems course, during which the study was conducted, started in September 2022. The first task, P1, took place on Tuesday, December 6th 2022, while the second, P2, took place on Tuesday, December 13th 2022.

Between the start of the course and P1, the participants had never dealt with TDD, while they were somewhat familiar with unit testing and iterative test-last development. In the weeks before P1, TDD was introduced to the participants via some lectures; also had taken part in ... training sessions on TDD and completed some homework by using this development practice.



\section {Analysis Procedure}
The gathered experimental data were analyzed according to the following procedure:
\begin{enumerate}
    \item \textbf{Descriptive Statistics}: in order to provide an overview of the distributions of the dependent variables, we calculated a set of summary statistics, including the mean, median, and standard deviation (SD). Additionally, we employed box plots to graphically summarize these distributions.
\end{enumerate}


\section{Results}
In this section we will report the values observed for each dependent variable.
Besides the tables, box plot charts will be used to visualize the values assumed by the dependent variables.
A box plot chart is a type of chart often used in explanatory data analysis; it visually shows the distribution of numerical data and skewness through displaying the data quartiles (or percentiles) and averages.

Box plot definitions:
\begin{itemize}
    \item \textbf{Minimum value}: the lowest value, excluding outliers (shown at the end of the lower whisker).
    \item \textbf{Maximum value}: the highest score, excluding outliers (shown at the end of the upper whisker).
    \item \textbf{Median}: marks the mid-point of the data and is shown by the line that divides the box into two parts. Half the values are greater than or equal to this value and half are less than this value.
    \item \textbf{Inter-quartile range}: The middle “box” represents the middle 50\% of values for the group. The range of values from lower to upper quartile is referred to as the inter-quartile range. The middle 50\% of scores fall within the inter-quartile range.
    \item \textbf{Upper quartile}: 75\% of the scores fall below the upper quartile.
    \item \textbf{Lower quartile}: 25\% of scores fall below the lower quartile.
    \item \textbf{Whiskers}: the upper and lower "whiskers" represent scores outside the middle 50\% (i.e. the lower 25\% of scores and the upper 25\% of scores).
    \item \textbf{Outliers}: observations that are numerically distant from the rest of the data. They are defined as data points that are located outside the whiskers of the box plot, and are represented by a dot.
\end{itemize}

\noindent To provide an example of the kind of information that a box plot chart can provide, please consider the following figure displaying four student groups' opinions on a subject:


Some observations that can be made include:
\begin{itemize}
    \item The box plot is comparatively short (see box plot  (2)). This suggests that overall the student have a high level of agreement and therefore the values are very similar between each other.
    \item The box plot is comparatively tall (see box plots (1) and (3)). This, on the other hand, suggests students hold quite different opinions about this aspect or sub-aspect.
    \item Obvious differences between box plots (see box plots (1) and (2), (1) and (3), or (2) and (4)). Any obvious difference between box plots for comparative groups is worthy of further investigation.
    \item The 4 sections of the box plot are uneven in size (see box plot (1)). This shows that many students have similar views at certain parts of the scale, but in other parts of the scale students are more variable in their views. The long upper whisker in the example means that students views are varied among the most positive quartile group, and very similar for the least positive quartile group. 
    \item Same median, different distribution (see box plots (1), (2), and (3)). The medians (which generally will be close to the average) are all at the same level. However, the box plots in these examples show very different distributions of views. It's always important to consider the pattern of the whole distribution of responses in a box plot.
\end{itemize}

\noindent\textbf{Task 1}: The following table display the values for the variables measured for the first experimental task, IntelligentOffice, for the two groups, in each of the two conditions.
\\ \  \\
\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}| }
    \hline
        \multicolumn{6}{|c|}{Task 1 - TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std \\
    \hline
        QLTY & 73 & 96 & 81.12 & 77.77 & 10.73 \\
        PROD & 72 & 96 & 83 & 82 & 10 \\
        TEST & 8 & 10 & 9.5 & 10 & 1 \\
        CYC & 21 & 28 & 24.75 & 25 & 2.87 \\
        COG & 14 & 25 & 19 & 18.5 & 4.69 \\
        LOC & 154 & 195 & 167 & 159.5 & 18.95 \\
    \hline
\end{tabular}
\\ \  \\

\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|}
    \hline
        \multicolumn{6}{|c|}{Task 1 - NO-TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std\\
    \hline
        QLTY & 65.55 & 82 & 75.35 & 78.77 & 7.43 \\
        PROD & 56 & 84 & 76 & 80 & 11.66 \\
        TEST & 0 & 12 & 3.8 & 0 & 5.49 \\
        CYC & 12 & 18 & 15.6 & 16 & 2.19 \\
        COG & 9 & 17 & 14 & 15 & 3 \\
        LOC & 74 & 157 & 111.6 & 100 & 33.69 \\
    \hline
\end{tabular}
\\ \  \\


\begin{figure}[H]
    \centering
    \includegraphics[width=10cm, scale=0.5]{figures/box plots/task1/p1_condition_qlty_bp.png}
    \caption{Box plot for $QLTY$ in task 1}
    \label{fig: Box plot for QLTY in task 1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm, scale=0.5]{figures/box plots/task1/p1_condition_prod_bp.png}
    \caption{Box plot for $PROD$ in task 1}
    \label{fig: Box plot for PROD in task 1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{figures/box plots/task1/p1_condition_test_bp.png}
    \caption{Box plot for $TEST$ in task 1}
    \label{fig: Box plot for TEST in task 1}
\end{figure}



\noindent \textbf{Task 2}: The following table display the values for the variables measured for the second experimental task, CleaningRobot, for the two groups, in each of the two conditions.
\\ \  \\
\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|}
    \hline
        \multicolumn{6}{|c|}{Task 2 - TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std\\
    \hline
        QLTY & 0 & 100 & 74.44 & 100 & 43.31 \\
        PROD & 8 & 100 & 38.6 & 21 & 37.35 \\
        TEST & 0 & 13 & 5.4 & 3 & 5.12 \\
        CYC & 9 & 19 & 12 & 10 & 4.06 \\
        COG & 2 & 40 & 12.8 & 4.0 & 15.91 \\
        LOC & 80 & 203 & 128 & 115 & 45.61 \\
    \hline
\end{tabular}


\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|}
    \hline
        \multicolumn{6}{|c|}{Task 2 - NO-TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std\\
    \hline
        QLTY & 74 & 94.43 & 83.07 & 81.94 & 10.17 \\
        PROD & 52 & 73 & 60.5 & 58.5 & 10.24 \\
        TEST & 5 & 12 & 9 & 9.5 & 2.94 \\
        CYC & 16 & 36 & 23.5 & 21 & 9 \\
        COG & 11 & 49 & 29 & 28 & 15.57 \\
        LOC & 178 & 260 & 207.5 & 196 & 37.11 \\
    \hline
\end{tabular}

\textbf{Tasks 1 \& 2}:

\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|}
    \hline
        \multicolumn{6}{|c|}{Task 1 \& 2 - TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std\\
    \hline
        QLTY & 0 & 100 & 77.41 & 82 & 31.52 \\
        PROD & 8 & 100 & 58.33 & 72 & 35.76 \\
        TEST & 0 & 13 & 7.22 & 8 & 4.26 \\
        CYC & 9 & 28 & 17.66 & 19 & 7.51 \\
        COG & 2 & 40 & 15.55 & 14 & 12.06 \\
        LOC & 80 & 203 & 145.33 & 154 & 39.97 \\
    \hline
\end{tabular}

\noindent
\begin{tabular}{ |p{2cm}||p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|p{1.6cm}|}
    \hline
        \multicolumn{6}{|c|}{Task 1 \& 2 - NO-TDD} \\
    \hline
        Metric & Min & Max & Mean & Median & Std\\
    \hline
        QLTY & 65.55 & 94.43 & 78.78 & 78.77 & 9.11 \\
        PROD & 52 & 84 & 69.11 & 73 & 13.22 \\
        TEST & 0 & 12 & 6.11 & 7.0 & 5.08 \\
        CYC & 12 & 36 & 19.11 & 16 & 7.07 \\
        COG & 9 & 49 & 20.66 & 15 & 12.56 \\
        LOC & 74 & 260 & 154.22 & 157 & 60.32 \\
    \hline
\end{tabular}


\section{Discussion}