\section{Related Work}
In the past, the Empirical Software Engineering community has taken interest into the investigation of the effects of TDD on several outcomes \cite{DBLP:conf/esem/FucciS0SSUTJO16} \cite{DBLP:journals/tse/ErdogmusMT05} \cite{DBLP:journals/infsof/Madeyski10}, including the ones of interest for this study—\ie, software/functional quality and productivity. These studies are summarized in Systematic Literature Reviews (\slrs) and meta-analyses (\eg \cite{DBLP:journals/infsof/BissiNE16, DBLP:journals/infsof/MunirMP14, DBLP:journals/tse/RafiqueM13, TDDEffective}).
The \slr by Turhan \etal \cite{TDDEffective} includes 32 primary studies (2000-2009). The gathered evidence shows a moderate effect in favor of \tdd on quality, while results on productivity is inconclusive, namely there is no decisive advantage on productivity for employing \tdd. Bissi \etal \cite{DBLP:journals/infsof/BissiNE16} conducted an \slr that includes 27 primary studies (1999-2014). 
Similarly to Turhan \etal \cite{TDDEffective}, the authors observed an improvement of functional quality due to \tdd, while results are inconclusive for productivity. Rafique and Misic \cite{DBLP:journals/tse/RafiqueM13} conducted a meta-analysis of 25 controlled experiments (2000-2011). The authors observed a small effect in favor of \tdd on functional quality, while again for productivity the results are inconclusive. 
Finally, Munir et al. \cite{DBLP:journals/infsof/MunirMP14,} in their \slr classifies 41 primary studies (2000-2011) according to the combination of their rigor and relevance. The authors found different conclusions for both functional quality and productivity in each classification.

An example of long-term investigation is the one by Marchenko et al. \cite{DBLP:conf/xpu/MarchenkoAI09}. Theauthors conducted a three-year-long case study about the use of \tdd at Nokia-Siemens Network. They observed and interviewed eight participants (one Scrum master, one product owner, and six developers) and then ran qualitative data analyses. The participants perceived TDD as important for the improvement of their code from a structural and functional perspective. Moreover, productivity increased due to the team improved confidence with the code base. The results show that \tdd was not suitable for bug fixing, especially when bugs are difficult to reproduce (e.g., when a specific environment setup is needed) or for quick experimentation due to the extra effort required for testing. The authors also reported some concerns regarding the lack of a solid architecture when applying \tdd.

Beller \etal \cite{DBLP:journals/tse/BellerGPPAZ19} executed a long-term study in-the-wild covering 594 open-source projects over the course of 2.5 years. They found that only 16 developers use \tdd more than 20\% of the time when making changes to their source code.
Moreover, TDD was used in only 12\% of the projects claiming to do so, and for the majority by experienced developers.

Borle \etal \cite{DBLP:journals/ese/BorleFSGH18} conducted a retrospective analysis of (Java) projects, hosted on GitHub, that adopted \tdd to some extent. The authors built sets of \tdd projects that differed one another based on the extent to which \tdd was adopted within these projects. The sets of \tdd projects were then compared to control sets so as to determine whether \tdd had a significant impact on the following characteristics: average commit velocity, number of bug-fixing commits, number of issues, usage of continuous integration, and number of pull requests. The results did not suggest any significant impact of \tdd on the above-mentioned characteristics.

Latorre \cite{DBLP:journals/tse/Latorre14} studied the capability of 30 professional software developers of different seniority levels (junior, intermediate, and expert) to develop a complex 4 software system by using \tdd. The study targeted the learnability of TDD since the participants did not know that technique before participating in the study. The longitudinal one-month study started after giving the developers, proficient in Java and unit testing, a tutorial on \tdd. After only a short practice session, the participants were able to correctly apply \tdd (e.g., following the prescribed steps). They followed the \tdd cycle between 80\% and 90\% of the time, but initially, their performance depended on experience. The seniors needed only few iterations, whereas intermediates and juniors needed more time to reach a high level of conformance to \tdd. Experience had an impact on performance—when using \tdd, only the experts were able to be as productive as they were when applying a traditional development methodology (measured during the initial development of the system). According to the junior participants, refactoring and design decision hindered their performance. Finally, experience did not have an impact on long-term functional quality. The results show that all participants delivered functionally correct software regardless of their seniority. Latorre [15] also provides initial evidence on the retainment of \tdd. Six months after the study investigating the learnability of \tdd, three developers, among those who had previously participated in that study, were asked to implement a new functionality. The results from this preliminary investigation suggest that developers retain \tdd in terms of developers' performance and conformance to \tdd.
Although the above-mentioned studies [15, 16, 3, 5] have taken a longitudinal perspective when studying \tdd, none of them has mainly focused on the effect of \tdd applied to the development of \ess.


\section{Testing Embedded Systems}
Garousi \etal \cite{DBLP:journals/infsof/GarousiFKY18} provided a systematic literature mapping for \es testing by reviewing 312 papers, focusing on types of testing activity, types of test artifacts generated, and the types of industries in which studies have focused. As the word cloud presented in the survey suggests, topics such as model-based and automated/automatic (testing), (test-case) generation, and control systems are among the most popular ones. Most of the review papers (137 of 312, around 43.9\%) present solution proposals without rigorous empirical studies; 98 (31.4\%) papers are weak empirical studies (validation re-
search). 36 (11.5\%) are experience papers. 34 are strong empirical studies (evaluation research). 2 and 5 papers, respectively, are philosophical and opinion papers.
In terms of level of testing considered in the papers, most of them (233 papers) considered system testing. 89 and 36 papers, respectively, focused on unit and integration testing. By focusing on unit testing, two of the sources (\cite{4428578}, \cite{DBLP:conf/isese/GuanOA06}) applied \tdd to embedded software. Several practical examples of automated unit test code were provided.
As for the type of test activities, there is a good mix of papers proposing techniques and tools for each of the test activities, with a major focus on test execution, automation and criteria-based test case design (\eg based on code coverage).


\cite{DBLP:journals/software/GarousiFKY18}


Often, quality in embedded software is generally tied to platform-specific testing tools geared towards debugging \cite{TDDEmbeddedSoftware}.
\dots


Applying TDD practices to \ess could potentially result in a series of benefits:
\begin{itemize}
    \item \dots
\end{itemize}


\begin{itemize}
    \item Reduce risk by verifying production code, independent of hardware, before hardware is ready or when hardware is expensive and scarce.
    \item Reduce the number of long target compile, link, and upload cycles that are executed by removing bugs on the development system.
    \item Reduce debug time on the target hardware where problems are more difficult to find and fix.
    \item Isolate hardware/software interaction issues by modeling hardware interactions in the tests.
    \item Improve software design through the decoupling of modules from each other and the hardware. Testable code is by necessity, modular.
\end{itemize}


\noindent In \cite{TDDEC}, the author proposes the "Embedded TDD Cycle", as a pipeline made of the following steps:
\begin{enumerate}
    \item \textbf{TDD micro-cycle}: this first stage is the one run most frequently, usually every few minutes. During this stage, a bulk of code is written in TDD fashion, and compiled to run on the host development system: doing so gives the developer fast feedback, not encumbered by the constraints of hardware reliability and/or availability, since there are no target compilers or lengthy upload processes. Furthermore, the development system should be a proven and stable execution environment, and usually has a richer debugging environment compared to the target platform. 
    Running the code on the development system, when it is eventually going to run in a foreign environment can be risky, so it's best to confront that risk regularly.
    \item \textbf{Compiler Compatibility Check}: periodically compile for the target environment, using the cross-compiler expected to be used for production compilations; this stage can be seen as an early warning system for any compiler incompatibilities, since it warns the developer of any porting issue, such as unavailable header files, incompatible language support, and missing language features. As a result, the written code only uses facilities available in both development environments.
    A potential issue at this stage is that in early ES development, the tool chain may not yet be decided, and this compatibility check cannot be performed: in this case, developers should take their best guess on the tool chain and compile against that compiler.
    Finally, this stage should not run with every code change; instead, a target cross-compile should take place whenever a new language feature is used, a new header file is included or a new library call is performed.
    \item \textbf{Run unit tests in an evaluation board}: compiled code could potentially run differently in the host development system and the target embedded processor. In order to mitigate this risk, developers can run the unit tests on an evaluation board; with this, any behavior differences between environments would emerge, ad since runtime libraries are usually prone to bugs \cite{TDDEC}, the risk is real. If it's late in the development cycle, and a reliable target hardware is available, this stage may appear unnecessary.
    \item \textbf{Run unit tests in the target hardware}: the objective here is again to run the test suite, however this time doing so while exercising the real hardware. One additional aspect to this stage is that developers could also run target hardware-specific tests. These tests allow developers to characterize or learn how the target hardware behaves. An additional challenge in this stage is limited memory in the target. The entire unit test suite may not fit into the target. In that case, the tests can be reorganized into separate test suites, where each suite fits in memory. This, however, does result in more complicated build automation process.
    \item \textbf{Run acceptance tests in the target hardware}: Finally, in order to make sure that the product features work, automated and manual acceptance tests are run in the target environment. Here developers have to make sure that any of the hardware-dependent code that can't be fully tested automatically is tested manually.
\end{enumerate}